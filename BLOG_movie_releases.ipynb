{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b015a2-409a-4a4c-bb08-b5374d1ec37b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Movie Theatre companies are somewhat easy to analyze. Taking a quick look at their earnings report, you'll see majority of their revenue are on Admission and Food & Bev. sales. And these are extremely dependent on the movies that are made and released. For example, with the huge success of Barbie and Oppenheimer in Q2 2023, AMC recorded their highest Admission revenue in over the past 3 years. In essence, if movies do well in theatres, then AMC does well. So in this series, we will be analyzing box office sales and seeing if AMC is worth investing in right before their earnings.   \n",
    "\n",
    "In this part, you will see how we will download and clean the data using Python and SQL.\n",
    "\n",
    "Luckily for us, box office numbers and AMC earnings reports are publicly available online. However, we cannot simply click a button to download all the data necessary, so we will write some code to obtain the data.\n",
    "\n",
    "For our box office data we will be using the boxofficemojo.com website which posts daily sales data for each movie. For AMC revenue, we will be accessing their earnings reports posted on their website. Then we will be uploading all this data onto our SQL server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e72651-e82b-4259-82fb-5e6fce02f08e",
   "metadata": {},
   "source": [
    "## The Code\n",
    "\n",
    "First and foremost, if you want to follow along and run through the code on your own, you will obviously need Python and SQL up and running. For this series, I will be using SQL Server.\n",
    "\n",
    "Now, we will import the necessary packages to help us do the heavy lifting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35bac028-ca14-42c1-be77-ec7011ed9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lxml\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "#supress annoying warnings on Jupyter Lab - don't do this if you're still learning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#necessary to connect to our SQL Server\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import URL\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c9b176-6479-4457-8f51-48c3d71bfbbe",
   "metadata": {},
   "source": [
    "Once we have imported the necessary packages, we will now analyze the boxofficemojo website to understand how we will scrape the data. \n",
    "\n",
    "Going to the Calendar page we see the url change consistently depending on the month and year selected on the dropdown. For example, when I change the month and year to November 2022, we see the url change to boxofficemojo.com/calendar/2022-11-01/ and movie releases for that particular month. So this tells us we will need to create a list or a dictionary to loop through all the month and years. Also, when making our requests, we know our base string will be boxofficemojo.com/calendar/ while we make the latter end dynamic, changing only the date in the format of 'YYYY-mm-dd'.\n",
    "\n",
    "Below is the dictionary I have made that we can loop through. I'm sure there's a way to make this on Python, but I decided to use Excel and just drag down on the cells to create this in less than a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f837fdf-c7d7-4774-90d2-13cc0b7289e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {\n",
    "    '2017-01-01':'Jan',\n",
    "    '2017-02-01':'Feb',\n",
    "    '2017-03-01':'Mar',\n",
    "    '2017-04-01':'Apr',\n",
    "    '2017-05-01':'May',\n",
    "    '2017-06-01':'Jun',\n",
    "    '2017-07-01':'Jul',\n",
    "    '2017-08-01':'Aug',\n",
    "    '2017-09-01':'Sep',\n",
    "    '2017-10-01':'Oct',\n",
    "    '2017-11-01':'Nov',\n",
    "    '2017-12-01':'Dec',\n",
    "    '2018-01-01':'Jan',\n",
    "    '2018-02-01':'Feb',\n",
    "    '2018-03-01':'Mar',\n",
    "    '2018-04-01':'Apr',\n",
    "    '2018-05-01':'May',\n",
    "    '2018-06-01':'Jun',\n",
    "    '2018-07-01':'Jul',\n",
    "    '2018-08-01':'Aug',\n",
    "    '2018-09-01':'Sep',\n",
    "    '2018-10-01':'Oct',\n",
    "    '2018-11-01':'Nov',\n",
    "    '2018-12-01':'Dec',\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c092f-35d6-4f9e-97c5-5e0df96f69a5",
   "metadata": {},
   "source": [
    "Next we will write a function to scrape all the movies released in that particular month and obtain the url to be able to access the daily box office sales for that particular movie. \n",
    "\n",
    "We know we will run a loop through our dictionary we created so for our first function we will need to pass two arguments, the url to access the page and the month for labelling purposes. The output of this function will be a dataframe containing the Title of the movie, the URL, Distributor and if it's a wide release or limited release movie.\n",
    "\n",
    "See comments in the code for the justification of each line I write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea5c85a-e386-4eff-a07e-8b5d3d6aa656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_release_processing(url, month):\n",
    "    'input url, returns dataframe'\n",
    "    s1 = pd.read_html(url, extract_links='all') #reads the table present in the page and extracts the links from the table\n",
    "    \n",
    "    s2 = s1[0]\n",
    "    s2.columns = ['Raw_Movie', 'Raw_Distributor','Raw_Scale'] #change column names to something more understandable\n",
    "\n",
    "    #in this next block of code, when adding the argument extract_links='all', it actually returns a tuple in each column so we will split that into separate columns\n",
    "    s2[['Movie','M_URL']] = pd.DataFrame(s2['Raw_Movie'].tolist())\n",
    "    s2[['Distributor','Drop_1']] = pd.DataFrame(s2['Raw_Distributor'].tolist())\n",
    "    s2[['Scale','Drop_2']] = pd.DataFrame(s2['Raw_Scale'].tolist())\n",
    "\n",
    "    #creating a column for labelling purposes\n",
    "    s2['Release_Month'] =  month \n",
    "\n",
    "    #list of columns to drop because they are either empty or we don't care about them\n",
    "    drop_list = [\n",
    "    'Raw_Movie',\n",
    "    'Raw_Distributor',\n",
    "    'Raw_Scale',\n",
    "    'Drop_1',\n",
    "    'Drop_2'\n",
    "    ]\n",
    "    s3 = s2.drop(drop_list, axis=1) #drop columns I don't care about\n",
    "\n",
    "    s4 = s3[s3['M_URL'].str.contains(\"None\")==False] #remove rows with no URLs (basically empty rows scraped)\n",
    "    return s4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c9c39-9fde-4620-a609-e39d08770d74",
   "metadata": {},
   "source": [
    "### Example Output of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff46f765-76c2-4316-8b06-fa7433f6410b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>M_URL</th>\n",
       "      <th>Distributor</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Release_Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Gaga: A True Story of Love and Dance  Biog...</td>\n",
       "      <td>/release/rl1064666625/?ref_=bo_rs_table_1</td>\n",
       "      <td>Abramorama</td>\n",
       "      <td>Limited</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lure  Drama  Fantasy  Horror  Musical  Thr...</td>\n",
       "      <td>/release/rl285246977/?ref_=bo_rs_table_2</td>\n",
       "      <td>Janus Films</td>\n",
       "      <td>Limited</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Irreplaceable  Comedy  Drama  With: François C...</td>\n",
       "      <td>/release/rl2097645057/?ref_=bo_rs_table_3</td>\n",
       "      <td>Distrib Films</td>\n",
       "      <td>Limited</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rings  Drama  Horror  Mystery  Romance  With: ...</td>\n",
       "      <td>/release/rl275547649/?ref_=bo_rs_table_4</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>Wide</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Space Between Us  Drama  Romance  Sci-Fi  ...</td>\n",
       "      <td>/release/rl1216120321/?ref_=bo_rs_table_5</td>\n",
       "      <td>STX Entertainment</td>\n",
       "      <td>Wide</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Movie  \\\n",
       "0  Mr. Gaga: A True Story of Love and Dance  Biog...   \n",
       "1  The Lure  Drama  Fantasy  Horror  Musical  Thr...   \n",
       "3  Irreplaceable  Comedy  Drama  With: François C...   \n",
       "5  Rings  Drama  Horror  Mystery  Romance  With: ...   \n",
       "6  The Space Between Us  Drama  Romance  Sci-Fi  ...   \n",
       "\n",
       "                                       M_URL         Distributor    Scale  \\\n",
       "0  /release/rl1064666625/?ref_=bo_rs_table_1          Abramorama  Limited   \n",
       "1   /release/rl285246977/?ref_=bo_rs_table_2         Janus Films  Limited   \n",
       "3  /release/rl2097645057/?ref_=bo_rs_table_3       Distrib Films  Limited   \n",
       "5   /release/rl275547649/?ref_=bo_rs_table_4  Paramount Pictures     Wide   \n",
       "6  /release/rl1216120321/?ref_=bo_rs_table_5   STX Entertainment     Wide   \n",
       "\n",
       "  Release_Month  \n",
       "0           Feb  \n",
       "1           Feb  \n",
       "3           Feb  \n",
       "5           Feb  \n",
       "6           Feb  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_dict = {\n",
    "    '2017-01-01':'Jan',\n",
    "    '2017-02-01':'Feb'}\n",
    "\n",
    "calend_url = 'https://www.boxofficemojo.com/calendar/{date}/'\n",
    "\n",
    "for j, k in month_dict.items():\n",
    "    test_url = calend_url.format(date=j) #creating the url\n",
    "    output = month_release_processing(test_url, k)\n",
    "\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bff374-13cc-4c91-b224-4ae3c4bcf05e",
   "metadata": {},
   "source": [
    "Here we see the output of our code. The M_URL column is an important one because we can now access the daily box office sales for that particular movie.\n",
    "\n",
    "The next thing we have to do now is to loop through the movie urls. So we will create a dictionary to loop through the urls and label it. See comments in the code to understand justification for each line written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e9ca489-25cf-428f-af77-377941aa89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(df):\n",
    "    'input dataframe returns list of dictionaries'\n",
    "    url_list = df[['Movie','M_URL']].to_dict('records') #converts our output into a dictionary\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbf6707-b56d-428b-a634-149d602bdce6",
   "metadata": {},
   "source": [
    "### Example Output of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c3c72ee-0c8e-4b88-b0ce-f86108bd5d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Movie': 'Mr. Gaga: A True Story of Love and Dance  Biography  Documentary  With: Ohad Naharin, Tzofia Naharin, Eliav Naharin, Judith Brin Ingber1 hr 40 minCast, Crew, and Company Info',\n",
       "  'M_URL': '/release/rl1064666625/?ref_=bo_rs_table_1'},\n",
       " {'Movie': 'The Lure  Drama  Fantasy  Horror  Musical  Thriller  With: Marta Mazurek, Michalina Olszanska, Kinga Preis, Andrzej Konopka1 hr 32 minCast, Crew, and Company Info',\n",
       "  'M_URL': '/release/rl285246977/?ref_=bo_rs_table_2'},\n",
       " {'Movie': 'Irreplaceable  Comedy  Drama  With: François Cluzet, Marianne Denicourt, Christophe Odent, Patrick Descamps1 hr 42 minCast, Crew, and Company Info',\n",
       "  'M_URL': '/release/rl2097645057/?ref_=bo_rs_table_3'},\n",
       " {'Movie': \"Rings  Drama  Horror  Mystery  Romance  With: Matilda Anna Ingrid Lutz, Alex Roe, Johnny Galecki, Vincent D'Onofrio1 hr 42 minCast, Crew, and Company Info\",\n",
       "  'M_URL': '/release/rl275547649/?ref_=bo_rs_table_4'},\n",
       " {'Movie': 'The Space Between Us  Drama  Romance  Sci-Fi  With: Gary Oldman, Asa Butterfield, Carla Gugino, Britt Robertson2 hrCast, Crew, and Company Info',\n",
       "  'M_URL': '/release/rl1216120321/?ref_=bo_rs_table_5'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_urls(output)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93356e9a-e69c-485d-97d6-12b2120840a0",
   "metadata": {},
   "source": [
    "Now that we are able to loop through each movie and access each page, we will now need to understand how each movie page is formatted.\n",
    "\n",
    "When we inspect the individual movie page there are three different types of results:\n",
    "\n",
    "1) Movie has an extremely limited release / only released online or DVD therefore has no data\n",
    "2) Movie has an extremely limited release therefore data is only available by Weekend or Week\n",
    "3) Movie has enough sales that daily data is available\n",
    "\n",
    "The third result is what we want to scrape. While there are dollars associated with the second result, it is not significant enough to warrant writing customized code for to process as the format is different from the daily table.\n",
    "\n",
    "Now that we have the url for each movie, we can now write some code to process each page and scrape the daily sales. See comments in the code to understand justification for each line written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7c7f3a3-2177-4b07-83d8-da8d2e566cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this for labelling purposes and returns a cleaner movie name\n",
    "def get_movie_title(url):\n",
    "    \"\"\"inside movie_rev_processing function\n",
    "    input url return text\"\"\"\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    html_page = urlopen(req).read()\n",
    "    soup = BeautifulSoup(html_page, 'lxml')\n",
    "    title = soup.find('h1', {\"class\":\"a-size-extra-large\"})\n",
    "    return title.get_text()\n",
    "\n",
    "def movie_rev_processing(url):\n",
    "    \"\"\"function inside a for loop\n",
    "    input a url (string), return dataframe\"\"\"\n",
    "\n",
    "    #added a try, except to ensure our code doesn't break\n",
    "    try:\n",
    "        s1 = pd.read_html(url, extract_links='all') #read url table and extract links to be able to parse the dates easily\n",
    "        s2 = s1[0]\n",
    "\n",
    "        #To catch movies with limited data (first or second result we described above)\n",
    "        #we default to NA and Zeros as there is probably no data available anyways\n",
    "        if len(s2.columns) < 11:\n",
    "            date_string = '1900-01-01'\n",
    "            data_ = {\n",
    "                'Category':['Less 11', 'Less 11'],\n",
    "                'DateString': ['NA', 'NA'],\n",
    "                'Date': [date_string, date_string],\n",
    "                'DOW': ['NA', 'NA'],\n",
    "                'DailyDollars': [0.0, 0.0],\n",
    "                'Theatres': [0.0, 0.0],\n",
    "                'Month': ['NA', 'NA'],\n",
    "                'Event': ['NA', 'NA']\n",
    "            }\n",
    "            df = pd.DataFrame(data = data_)\n",
    "            df['Date'] = [datetime.strptime(date_, '%Y-%m-%d').date() for date_ in df['Date']]\n",
    "            return df\n",
    "\n",
    "        #just in case there is weird data structures going on that we did not notice when inspecting movie pages\n",
    "        elif len(s2.columns) > 11:\n",
    "            date_string = '1900-01-01'\n",
    "            data_ = {\n",
    "                'Category':['Greater 11', 'Greater 11'],\n",
    "                'DateString': ['NA', 'NA'],\n",
    "                'Date': [date_string, date_string],\n",
    "                'DOW': ['NA', 'NA'],\n",
    "                'DailyDollars': [0.0, 0.0],\n",
    "                'Theatres': [0.0, 0.0],\n",
    "                'Month': ['NA', 'NA'],\n",
    "                'Event': ['NA', 'NA']\n",
    "            }\n",
    "            df = pd.DataFrame(data = data_)\n",
    "            df['Date'] = [datetime.strptime(date_, '%Y-%m-%d').date() for date_ in df['Date']]\n",
    "            return df\n",
    "\n",
    "        #this is the data we really care about\n",
    "        else:\n",
    "            #we add this list because when pandas reads the table and extracts links, the column names are weird so we will rename them\n",
    "            fix_cols = [\n",
    "                'Date',\n",
    "                'DOW',\n",
    "                'Rank',\n",
    "                'Daily',\n",
    "                '+-YD',\n",
    "                '+-LW',\n",
    "                'Theatres',\n",
    "                'Avg',\n",
    "                'To Date',\n",
    "                'Day',\n",
    "                'Estimated'\n",
    "            ]\n",
    "        \n",
    "            s2.columns = fix_cols #we rename the columns here\n",
    "\n",
    "            #in this block of code we will split each column as most don't have links\n",
    "            #we only care about the date column link because it shows the date in a cleaner format\n",
    "            #the date column when extracted by itself (no links) combines the holiday/event and is difficult to parse through as it's not consistent\n",
    "            #ex Christmas would be Dec25Christmas\n",
    "            s2[['DateString','D_URL']] = pd.DataFrame(s2['Date'].tolist())\n",
    "            s2[['DOW','Drop_1']] = pd.DataFrame(s2['DOW'].tolist())\n",
    "            s2[['DailyDollars','Drop_2']] = pd.DataFrame(s2['Daily'].tolist())\n",
    "            s2[['Theatres','Drop_3']] = pd.DataFrame(s2['Theatres'].tolist())\n",
    "\n",
    "            #we parse through the date column and clean it up\n",
    "            s2['P_Date'] = s2['D_URL'].apply(lambda st: st[st.find(\"date/\")+5:st.find(\"/?ref\")])\n",
    "\n",
    "            #now we create a new dataframe with the columns we only care about\n",
    "            s3 = s2[['DateString', 'P_Date', 'DOW', 'DailyDollars', 'Theatres']]\n",
    "        \n",
    "        \n",
    "            #adding event/holiday columns        \n",
    "            s3['Month'] = s3['DateString'].str[:4]\n",
    "            s3['PreDay'] = s3['DateString'].str[4:]\n",
    "            s3['DayCheck'] = [s[:2] if re.search('[A-Za-z]', s) != None else s[:2] for s in s3['PreDay']] #get day number\n",
    "            s3['EventCheck'] = [re.search('[A-Za-z]', event) if re.search('[A-Za-z]', event) != None else \"No Event\" for event in s3['DayCheck']] #checks for alphabet in string\n",
    "            s3['Event_start'] = [s.start() if s != \"No Event\" else \"NA\" for s in s3['EventCheck']] #gets starting position of non-number\n",
    "            s3['Event'] = s3['PreDay'].str[2:] #gets event name\n",
    "\n",
    "            #convert strings to float type to be able to do mathematical functions\n",
    "            s3['DailyDollars'] = s3['DailyDollars'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "            s3['Theatres'] = [float(str(i).replace(\",\", \"\")) for i in s3[\"Theatres\"]]\n",
    "            s3['Date'] = [datetime.strptime(date_, '%Y-%m-%d').date() for date_ in s3['P_Date']] #convert from string to date type\n",
    "\n",
    "            #set to pass to be able to filter later on\n",
    "            s3['Category'] = 'Pass'\n",
    "        \n",
    "            s4 = s3[['Category','DateString', 'Date', 'DOW', 'DailyDollars', 'Theatres', 'Month','Event']]\n",
    "            \n",
    "            return s4\n",
    "\n",
    "    #catch just in case and won't break the code\n",
    "    except:\n",
    "        date_string = '1900-01-01'\n",
    "        data_ = {\n",
    "            'Category':['No Data', 'No Data'],\n",
    "            'DateString': ['NA', 'NA'],\n",
    "            'Date': [date_string, date_string],\n",
    "            'DOW': ['NA', 'NA'],\n",
    "            'DailyDollars': [0.0, 0.0],\n",
    "            'Theatres': [0.0, 0.0],\n",
    "            'Month': ['NA', 'NA'],\n",
    "            'Event': ['NA', 'NA']\n",
    "        }\n",
    "        df = pd.DataFrame(data = data_)\n",
    "        df['Date'] = [datetime.strptime(date_, '%Y-%m-%d').date() for date_ in df['Date']]\n",
    "        return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3166f4-e4b5-47f4-8aa2-b6ab3483af9b",
   "metadata": {},
   "source": [
    "### Example output of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06258a5a-2d43-4b49-bff2-1915237681f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barbie'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_url = 'https://www.boxofficemojo.com/release/rl1077904129/?ref_=bo_tt_gr_1'\n",
    "get_movie_title(ex_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c385c355-6f07-4c87-b2d5-168d6a362604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>DateString</th>\n",
       "      <th>Date</th>\n",
       "      <th>DOW</th>\n",
       "      <th>DailyDollars</th>\n",
       "      <th>Theatres</th>\n",
       "      <th>Month</th>\n",
       "      <th>Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass</td>\n",
       "      <td>Jul 21</td>\n",
       "      <td>2023-07-21</td>\n",
       "      <td>Friday</td>\n",
       "      <td>70503178.0</td>\n",
       "      <td>4243.0</td>\n",
       "      <td>Jul</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass</td>\n",
       "      <td>Jul 22</td>\n",
       "      <td>2023-07-22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>47812356.0</td>\n",
       "      <td>4243.0</td>\n",
       "      <td>Jul</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass</td>\n",
       "      <td>Jul 23</td>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>43706510.0</td>\n",
       "      <td>4243.0</td>\n",
       "      <td>Jul</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass</td>\n",
       "      <td>Jul 24</td>\n",
       "      <td>2023-07-24</td>\n",
       "      <td>Monday</td>\n",
       "      <td>26105167.0</td>\n",
       "      <td>4243.0</td>\n",
       "      <td>Jul</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pass</td>\n",
       "      <td>Jul 25</td>\n",
       "      <td>2023-07-25</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>26003569.0</td>\n",
       "      <td>4243.0</td>\n",
       "      <td>Jul</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category DateString        Date       DOW  DailyDollars  Theatres Month  \\\n",
       "0     Pass     Jul 21  2023-07-21    Friday    70503178.0    4243.0  Jul    \n",
       "1     Pass     Jul 22  2023-07-22  Saturday    47812356.0    4243.0  Jul    \n",
       "2     Pass     Jul 23  2023-07-23    Sunday    43706510.0    4243.0  Jul    \n",
       "3     Pass     Jul 24  2023-07-24    Monday    26105167.0    4243.0  Jul    \n",
       "4     Pass     Jul 25  2023-07-25   Tuesday    26003569.0    4243.0  Jul    \n",
       "\n",
       "  Event  \n",
       "0        \n",
       "1        \n",
       "2        \n",
       "3        \n",
       "4        "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_rev_processing(ex_url).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563579de-0257-4d22-b3e8-dd014390f531",
   "metadata": {},
   "source": [
    "Now that we have all the necessary functions to scrape the data, we will now need to write a function to upload the data onto our SQL server. Below is the code to upload the data onto our SQL server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b393ac6-d503-4b78-a976-ce4e9d7f12a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"DRIVER={ODBC Driver 17 for SQL Server};SERVER=localhost;DATABASE=moviereleases;UID=dell;PWD=password\"\n",
    "connection_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "def insert_to_db(df, tbl_name, eng):\n",
    "    \"\"\"df = dataframe, tbl_name for labelling purposes and the engine\"\"\"\n",
    "    df.to_sql(tbl_name, con = eng, if_exists = 'append')#uploads to SQL\n",
    "    return \"Inserted \" + \" to \"+tbl_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c456af5-06ea-47dd-9b3c-90c74f119d70",
   "metadata": {},
   "source": [
    "## Almost done. Now we make the loop\n",
    "\n",
    "Now that we have all the functions to scrape and upload the data, we now write the code to loop through it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde94eb-7149-4967-929f-5c012260d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls we will be using\n",
    "calend_url = 'https://www.boxofficemojo.com/calendar/{date}/'\n",
    "base_url = 'https://www.boxofficemojo.com{movie_}'\n",
    "\n",
    "\n",
    "# first for loop to loop through each month and the movie releases\n",
    "for date, month in month_dict.items():\n",
    "    m_url = calend_url.format(date=date)\n",
    "    monthly_releases = month_release_processing(m_url, month)\n",
    "\n",
    "    #upload the first table (monthly releases page) to SQL server\n",
    "    insert_to_db(monthly_releases, 'monthlyreleases', engine)\n",
    "    print(\"uploaded monthly releases for the month of \"+date)\n",
    "\n",
    "    #add a sleep function so we don't get our IP restricted\n",
    "    time.sleep(3) \n",
    "\n",
    "    \n",
    "    #get individual movie urls\n",
    "    movie_urls = get_urls(monthly_releases)\n",
    "\n",
    "    #second for loop to loop through the urls we get\n",
    "    for movie in movie_urls:\n",
    "        movie_url = base_url.format(movie_=movie['M_URL'])\n",
    "        movie_db = movie_rev_processing(movie_url)\n",
    "\n",
    "        movie_db['url'] = movie['M_URL']\n",
    "        \n",
    "        #add a sleep function so we don't get our IP restricted\n",
    "        time.sleep(3)\n",
    "        movie_name = get_movie_title(movie_url)\n",
    "        movie_db['Movie'] = movie_name\n",
    "\n",
    "        #upload to SQL server\n",
    "        insert_to_db(movie_db, 'dailytable', engine)\n",
    "        print(\"uploaded \"+movie_name)\n",
    "        \n",
    "        #add a sleep function so we don't get our IP restricted\n",
    "        time.sleep(3)\n",
    "\n",
    "    print(\"finished \"+date)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3600f61-c375-4203-9682-90ddcdb18389",
   "metadata": {},
   "source": [
    "## We're almost done. We just need to do some clean up\n",
    "\n",
    "Now that we have scraped all the data we needed, we have to clean up our table as their are duplicates present in the data. For some reason the website will publish the same movie in separate months, creating duplicates in our data. We will use SQL to clean it up. While you might be wondering, \"Hey, why didn't we clean this earlier in the steps up above?\", well my response is, I didn't know there were duplicates until after I ran my code. And writing another function to clean it up is not worth re-running and waiting a few hours to loop through all these movies again.\n",
    "\n",
    "So what we will do is execute the following SQL code and it will remove our duplicatese\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce957e-13b9-4ad0-b6f9-1eaea7dd1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "-- ADDING UNIQUE ROW NUMBER\n",
    "\n",
    "SELECT *,  ROW_NUMBER() over (order by Movie, Date) as row_num\n",
    "INTO dev_table\n",
    "FROM dbo.dailytable\n",
    "\n",
    "\n",
    "--- SUBSTRING - ADDING MOVIE ID, MOVIE KEY, AND DUPLICATE INDICATOR COLUMNS\n",
    "\n",
    "ALTER TABLE dbo.dev_table\n",
    "ADD movie_id varchar(255),\n",
    "ADD moviekey varchar(255),\n",
    "ADD dupe_count INT\n",
    "\n",
    "UPDATE dbo.dev_table\n",
    "SET dbo.dev_table.movie_id = SUBSTRING(url,\n",
    "\t\tCHARINDEX('/release/',url) + len('/release/') ,\n",
    "\t\tcharindex('/?ref', url) - len('/release/') - 1)\n",
    "FROM dbo.dev_table\n",
    "\n",
    "UPDATE dbo.dev_table\n",
    "SET dbo.dev_table.moviekey = CONCAT(Date, Movie,movie_id)\n",
    "\n",
    "-- IDENTIFY DUPLICATES \n",
    "SELECT \n",
    "\t\te.moviekey,\n",
    "\t\te.row_num,\n",
    "\t\tT.rn\n",
    "INTO temp\n",
    "FROM moviereleases.dbo.dev_table e\n",
    "\tINNER JOIN\n",
    "\t(\n",
    "\tSELECT *,\n",
    "\trow_number() OVER (PARTITION BY moviekey order by row_num) rn\n",
    "\tFROM dbo.dev_table) T on e.moviekey = T.moviekey and e.row_num = T.row_num;\n",
    "\n",
    "-- ADDING VALUES TO OUR DUPE COUNT COLUMN\n",
    "UPDATE dbo.dev_table\n",
    "SET dbo.dev_table.dupe_count = dbo.temp.rn\n",
    "FROM dbo.dev_table LEFT JOIN dbo.temp\n",
    "ON dbo.dev_table.row_num = dbo.temp.row_num\n",
    "\n",
    "-- DELETING DUPLICATES\n",
    "DELETE FROM dbo.dev_table\n",
    "WHERE dupe_count > 1\n",
    "\n",
    "-- TABLE WE CARE ABOUT\n",
    "SELECT * FROM dev_table\n",
    "WHERE Category = 'Pass'\n",
    "ORDER BY Date, Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75e699-d01a-4568-8d9e-36332d0e2456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
